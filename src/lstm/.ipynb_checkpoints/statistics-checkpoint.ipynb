{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規表現\n",
    "def get_tag_id(text):\n",
    "    m = re.search(r'id=\"([0-9]+)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_ga_tag(text):\n",
    "    m = re.search(r'ga=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_o_tag(text):\n",
    "    m = re.search(r'o=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_ni_tag(text):\n",
    "    m = re.search(r' ni=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_ga_dep_tag(text):\n",
    "    m = re.search(r'ga_dep=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_o_dep_tag(text):\n",
    "    m = re.search(r'o_dep=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None\n",
    "def get_ni_dep_tag(text):\n",
    "    m = re.search(r' ni_dep=\"(.+?)\"', text)\n",
    "    if m: return m.group(1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/sango.m.ab/Desktop/research/data/annotated/'\n",
    "foldas = ['OC', 'OW', 'OY', 'PB', 'PM', 'PN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    def __init__(self, model_file_path):\n",
    "        model = gensim.models.word2vec.KeyedVectors.load_word2vec_format(model_file_path)\n",
    "        self.model = model\n",
    "\n",
    "    def word_to_vector(self, word):\n",
    "        if word and word in self.model.vocab:\n",
    "            return self.model[word]\n",
    "        else:\n",
    "            return np.zeros(200, dtype=np.float32)\n",
    "    def word_to_dataframe(self, word):\n",
    "        vector = self.word_to_vector(word)\n",
    "        if word == 'exo1':\n",
    "            vector = self.word_to_vector('僕')\n",
    "        elif word == 'exo2':\n",
    "            vector = self.word_to_vector('おまえ')\n",
    "        elif word == 'exog':\n",
    "            vector = self.word_to_vector('これ')\n",
    "        df = pd.DataFrame([word_vector])\n",
    "        df.columns = [f'word2vec:{i}' for i in range(200)]\n",
    "        df['word'] = word\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec('/Users/sango.m.ab/Downloads/entity_vector/entity_vector.model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.word_to_vector('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path):\n",
    "    sentence = ''\n",
    "    with open(file_path) as f:\n",
    "        for line in f:\n",
    "            if line[0] == '#':\n",
    "                continue\n",
    "            if line.strip() == 'EOS':\n",
    "                yield sentence\n",
    "                sentence = ''\n",
    "            else:\n",
    "                sentence += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_find_verb(sentence):\n",
    "    \"\"\"\n",
    "    動詞，形容詞，サ変名詞を対象\n",
    "    \"\"\"\n",
    "    word_number = 0 #何単語目に出現したか\n",
    "    for i, line in enumerate(sentence.split('\\n')):\n",
    "        if line[0] != '*':\n",
    "            word_number += 1\n",
    "        if '動詞' in line or '形容詞' in line or 'サ変可能' in line:\n",
    "            ga_case_id = get_ga_tag(line)\n",
    "            o_case_id = get_o_tag(line)\n",
    "            ni_case_id = get_ni_tag(line)\n",
    "            yield sentence_to_vector(sentence, word_number, ga_case_id, o_case_id, ni_case_id)\n",
    "        if line[0] == '*':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_to_dataframe(feature):\n",
    "    feature = feature.split(',')\n",
    "    df = pd.DataFrame([feature])\n",
    "    df.columns = [f'feature:{i}' for i in range(17)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_none():\n",
    "    df_word_vector = word2vec.word_to_dataframe('')\n",
    "    df_feature = feature_to_dataframe('*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*,*')\n",
    "    df_none = pd.merge(df_word_vector, df_feature, left_index=True, right_index=True, how='outer')\n",
    "    return df_none\n",
    "def make_df_exo1():\n",
    "    df_word_vector = word2vec.word_to_dataframe('exo1')\n",
    "    df_feature = feature_to_dataframe('代名詞,*,*,*,*,*,ボク,僕,*,*,*,*,漢,*,*,*,*')\n",
    "    df_exo1 = pd.merge(df_word_vector, df_feature, left_index=True, right_index=True, how='outer')\n",
    "    return df_exo1\n",
    "def make_df_exo2():\n",
    "    df_word_vector = word2vec.word_to_dataframe('exo2')\n",
    "    df_feature = feature_to_dataframe('代名詞,*,*,*,*,*,ワタクシ,私,*,*,*,*,和,*,*,*,*')\n",
    "    df_exo2 = pd.merge(df_word_vector, df_feature, left_index=True, right_index=True, how='outer')\n",
    "    return df_exo2\n",
    "def make_df_exog():\n",
    "    df_word_vector = word2vec.word_to_dataframe('exog')\n",
    "    df_feature = feature_to_dataframe('代名詞,*,*,*,*,*,ソレ,其れ,*,*,*,*,和,*,*,*,*')\n",
    "    df_exog = pd.merge(df_word_vector, df_feature, left_index=True, right_index=True, how='outer')\n",
    "    return df_exog\n",
    "\n",
    "def sentence_to_vector(sentence, verb_number, ga_case_id, o_case_id, ni_case_id):\n",
    "    df_none = make_df_none()\n",
    "    df_exo1 = make_df_exo1()\n",
    "    df_exo2 = make_df_exo2()\n",
    "    df_exog = make_df_exog()\n",
    "    df = pd.concat([df_none, df_exo1, df_exo2, df_exog])\n",
    "    word_number = 0 #何単語目に出現したか\n",
    "    phrase_count = 0 #文節のカウント\n",
    "    count_head_word_number = 0 #文節ごとの単語のカウント（主辞判定のため）\n",
    "    for i, line in enumerate(sentence.split('\\n')):\n",
    "        if line[0] == '*':\n",
    "            head_word_number = int(line.split()[3].split('/')[0])\n",
    "            count_head_word_number = 0\n",
    "            phrase_count += 1\n",
    "            continue\n",
    "        word_number += 1\n",
    "        word, feature, tag = line.split('\\t')\n",
    "        df_word_vector = word2vec.word_to_dataframe(word)\n",
    "        df_feature = feature_to_dataframe(feature)\n",
    "        df_ = pd.merge(df_word_vector, df_feature, left_index=True, right_index=True, how='outer')\n",
    "    #その他の素性\n",
    "        #形態素距離\n",
    "        df_['形態素距離'] = abs(word_number-verb_number)\n",
    "        #主辞\n",
    "        if count_head_word_number == head_word_number:\n",
    "            df_['主辞'] = 1\n",
    "        count_head_word_number += 1\n",
    "        #文節\n",
    "        df_['文節'] = phrase_count\n",
    "        #述語の場合はdepのタグ付けもいれる\n",
    "        if word_number == verb_number:\n",
    "            df_['is_verb'] = 1\n",
    "            ga_dep_tag = get_ga_dep_tag(tag)\n",
    "            df_['ga_dep_tag'] = ga_dep_tag\n",
    "            o_dep_tag = get_o_dep_tag(tag)\n",
    "            df_['o_dep_tag'] = o_dep_tag\n",
    "            ni_dep_tag = get_ni_dep_tag(tag)\n",
    "            df_['ni_dep_tag'] = ni_dep_tag\n",
    "        \n",
    "        #正解ラベルか確認して，正解を入れる．\n",
    "        tag_id = get_tag_id(tag)\n",
    "        if ga_case_id == tag_id:\n",
    "            df_['ga_case'] = 1\n",
    "        if o_case_id == tag_id:\n",
    "            df_['o_case'] = 1\n",
    "        if ni_case_id == tag_id:\n",
    "            df_['ni_case'] = 1\n",
    "\n",
    "        df = pd.concat([df, df_], ignore_index=True)\n",
    "        \n",
    "    if not df.get('ga_case').any():\n",
    "        if ga_case_id == 'exo1':\n",
    "            df.at[1, 'ga_case'] = 1\n",
    "        elif ga_case_id == 'exo2':\n",
    "            df.at[2, 'ga_case'] = 1\n",
    "        elif ga_case_id == 'exog':\n",
    "            df.at[3, 'ga_case'] = 1\n",
    "        else:\n",
    "            df.at[0, 'ga_case'] = 1\n",
    "    if not df.get('o_case').any():\n",
    "        if o_case_id == 'exo1':\n",
    "            df.at[1, 'o_case'] = 1\n",
    "        elif o_case_id == 'exo2':\n",
    "            df.at[2, 'o_case'] = 1\n",
    "        elif o_case_id == 'exog':\n",
    "            df.at[3, 'o_case'] = 1\n",
    "        else:\n",
    "            df.at[0, 'o_case'] = 1\n",
    "    if not df.get('ni_case').any():\n",
    "        if ni_case_id == 'exo1':\n",
    "            df.at[1, 'ni_case'] = 1\n",
    "        elif ni_case_id == 'exo2':\n",
    "            df.at[2, 'ni_case'] = 1\n",
    "        elif ni_case_id == 'exog':\n",
    "            df.at[3, 'ni_case'] = 1\n",
    "        else:\n",
    "            df.at[0, 'ni_case'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for sentence in load_file('/Users/sango.m.ab/Desktop/research/data/annotated/OC/00181_A_OC14_00057.cabocha'):\n",
    "    for df in sentence_find_verb(sentence):\n",
    "        df_list.append(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''* 0 1D 2/4 0.000000\n",
    "髪\t名詞,普通名詞,一般,*,*,*,カミ,髪,*,*,*,*,和,*,*,*,*\t_\n",
    "に\t助詞,格助詞,*,*,*,*,ニ,に,*,*,*,*,和,*,*,*,*\t_\n",
    "関し\t動詞,一般,*,*,サ行変格,連用形-一般,カンスル,関する,*,*,関する,*,混,*,*,*,*\t_\n",
    "て\t助詞,接続助詞,*,*,*,*,テ,て,*,*,*,*,和,*,*,*,*\t_\n",
    "の\t助詞,格助詞,*,*,*,*,ノ,の,*,*,*,*,和,*,*,*,*\t_\n",
    "* 1 3D 0/2 0.000000\n",
    "用語\t名詞,普通名詞,一般,*,*,*,ヨウゴ,用語,*,*,*,*,漢,*,*,*,*\t_\n",
    "です\t助動詞,*,*,*,助動詞-デス,終止形-一般,デス,です,*,*,です,*,和,*,*,*,*\t_\n",
    "が\t助詞,接続助詞,*,*,*,*,ガ,が,*,*,*,*,和,*,*,*,*\t_\n",
    "* 2 3D 1/3 0.000000\n",
    "「\t補助記号,括弧開,*,*,*,*,,「,*,*,*,*,記号,*,*,*,*\t_\n",
    "ブロー\t名詞,普通名詞,サ変可能,*,*,*,ブロー,ブロー,*,*,*,*,外,*,*,*,*\tga=\"exog\" id=\"1\" type=\"noun\"\n",
    "」\t補助記号,括弧閉,*,*,*,*,,」,*,*,*,*,記号,*,*,*,*\t_\n",
    "って\t助詞,副助詞,*,*,*,*,ッテ,って,*,*,*,*,和,*,*,*,*\t_\n",
    "、\t補助記号,読点,*,*,*,*,,、,*,*,*,*,記号,*,*,*,*\t_\n",
    "* 3 -1Z 0/2 0.000000\n",
    "何\t代名詞,*,*,*,*,*,ナニ,何,*,*,*,*,和,*,*,*,*\tga=\"1\" ga_dep=\"dep\" type=\"pred\"\n",
    "です\t助動詞,*,*,*,助動詞-デス,終止形-一般,デス,です,*,*,です,*,和,*,*,*,*\t_\n",
    "か\t助詞,終助詞,*,*,*,*,カ,か,*,*,*,*,和,*,*,*,*\t_\n",
    "？\t補助記号,句点,*,*,*,*,,？,*,*,*,*,記号,*,*,*,*\t_\n",
    "？\t補助記号,句点,*,*,*,*,,？,*,*,*,*,記号,*,*,*,*\t_\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sentence_to_vector(sentence, 14, '1', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     NaN\n",
       "2     NaN\n",
       "3     NaN\n",
       "4     NaN\n",
       "5     NaN\n",
       "6     NaN\n",
       "7     NaN\n",
       "8     NaN\n",
       "9     NaN\n",
       "10    NaN\n",
       "11    NaN\n",
       "12    NaN\n",
       "13    NaN\n",
       "14    NaN\n",
       "15    NaN\n",
       "16    NaN\n",
       "17    dep\n",
       "18    NaN\n",
       "19    NaN\n",
       "20    NaN\n",
       "21    NaN\n",
       "Name: ga_dep_tag, dtype: object"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ga_dep_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.merge(df2, df1, left_index=True, right_index=True, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7_x</th>\n",
       "      <th>8_x</th>\n",
       "      <th>9_x</th>\n",
       "      <th>...</th>\n",
       "      <th>7_y</th>\n",
       "      <th>8_y</th>\n",
       "      <th>9_y</th>\n",
       "      <th>10_y</th>\n",
       "      <th>11_y</th>\n",
       "      <th>12_y</th>\n",
       "      <th>13_y</th>\n",
       "      <th>14_y</th>\n",
       "      <th>15_y</th>\n",
       "      <th>16_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.440727</td>\n",
       "      <td>1.669914</td>\n",
       "      <td>0.870127</td>\n",
       "      <td>1.433319</td>\n",
       "      <td>-0.419108</td>\n",
       "      <td>-0.536237</td>\n",
       "      <td>-2.031504</td>\n",
       "      <td>0.385712</td>\n",
       "      <td>-0.2279</td>\n",
       "      <td>0.237499</td>\n",
       "      <td>...</td>\n",
       "      <td>詰める</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>詰める</td>\n",
       "      <td>*</td>\n",
       "      <td>和</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0_x       1_x       2_x       3_x       4_x       5_x       6_x  \\\n",
       "0 -0.440727  1.669914  0.870127  1.433319 -0.419108 -0.536237 -2.031504   \n",
       "\n",
       "        7_x     8_x       9_x  ...   7_y  8_y  9_y  10_y  11_y  12_y  13_y  \\\n",
       "0  0.385712 -0.2279  0.237499  ...   詰める    *    *   詰める     *     和     *   \n",
       "\n",
       "   14_y  15_y  16_y  \n",
       "0     *     *     *  \n",
       "\n",
       "[1 rows x 217 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df, df_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
